{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using [this](http://ai.stanford.edu/~amaas/data/sentiment/) dataset for binary sentiment classification. The dataset contains 25,000 highly polar movie reviews for training, and 25,000 for testing. To get the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext \n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "train_path = \"/Users/deena/Documents/Intersession/spark-nb/aclImdb/train/\"\n",
    "test_path =\"/Users/deena/Documents/Intersession/spark-nb/aclImdb/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_raw_pos = sc.textFile(train_path + \"pos/*.txt\")\n",
    "data_raw_neg = sc.textFile(train_path + \"neg/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt.'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that this is a whole review\n",
    "data_raw_pos.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample 20% of the data\n",
    "data_raw_pos = data_raw_pos.sample(False, 0.2, 1)\n",
    "data_raw_neg = data_raw_neg.sample(False, 0.2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of partitions\n",
    "data_raw_pos.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repartition\n",
    "num_partitions = 8\n",
    "data_raw_pos = data_raw_pos.repartition(num_partitions)\n",
    "data_raw_neg = data_raw_neg.repartition(num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529\n",
      "2529\n"
     ]
    }
   ],
   "source": [
    "# count 2529 elements\n",
    "print(data_raw_pos.count())\n",
    "print(data_raw_neg.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data cleaning: Remove stop words and punctuation\n",
    "def words(text):\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    word = regex.sub(\"\", text)\n",
    "    if len(word) > 2 and word.strip().lower() not in stopwords.words('english'):\n",
    "        return word.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams_pos = data_raw_pos.map(lambda x: x.split()).map(lambda x: [words(w) for w in x])\\\n",
    "    .map(lambda x: [w.strip() for w in x if w is not None])\\\n",
    "    .flatMap(lambda x: [x[i]+'_'+x[i+1] for i in range(0,len(x)-1)])\\\n",
    "    .map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y).sortBy(lambda x: x[1], ascending = False)\\\n",
    "    .map(lambda x: x[0]).take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigram_mapping(x, bigrams):\n",
    "    words = []\n",
    "    for i in range(0, len(x)-1):\n",
    "        if x[i]+'_'+x[i+1] in bigrams:\n",
    "            words.append(x[i]+'_'+x[i+1])\n",
    "        else:\n",
    "            words.append(x[i])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_words = data_raw_pos.map(lambda x: x.split()).map(lambda x: [words(w) for w in x])\\\n",
    "    .map(lambda x: [w.strip() for w in x if w is not None])\\\n",
    "    .flatMap(lambda x: bigram_mapping(x, bigrams_pos))#.flatMap(lambda x: x)\n",
    "data_pos = pos_words.map(lambda x: (x, 1))\n",
    "data_pos = data_pos.reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams_neg = data_raw_neg.map(lambda x: x.split()).map(lambda x: [words(w) for w in x])\\\n",
    "    .map(lambda x: [w.strip() for w in x if w is not None])\\\n",
    "    .flatMap(lambda x: [x[i]+'_'+x[i+1] for i in range(0,len(x)-1)])\\\n",
    "    .map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y).sortBy(lambda x: x[1], ascending = False)\\\n",
    "    .map(lambda x: x[0]).take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_words = data_raw_neg.map(lambda x: x.split()).map(lambda x: [words(w) for w in x])\\\n",
    "    .map(lambda x: [w.strip() for w in x if w is not None])\\\n",
    "    .flatMap(lambda x: bigram_mapping(x, bigrams_neg))#.flatMap(lambda x: x)\n",
    "data_neg = neg_words.map(lambda x: (x, 1))\n",
    "data_neg = data_neg.reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Implementation\n",
    "\n",
    "Computing count(pos) and count(neg):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_pos = data_pos.map(lambda x: x[1]).reduce(lambda x,y:x+y)\n",
    "count_neg = data_neg.map(lambda x: x[1]).reduce(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302041, 294762)\n"
     ]
    }
   ],
   "source": [
    "print(count_pos, count_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50136\n"
     ]
    }
   ],
   "source": [
    "## Getting V\n",
    "v1 = data_pos.map(lambda x: x[0]) # pos vocabulary\n",
    "v2 = data_neg.map(lambda x: x[0]) # neg vocabulary\n",
    "v = v1.union(v2)\n",
    "#v.count()\n",
    "v0 = v.distinct()\n",
    "V = v0.count()\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Denominators are different \n",
    "pos_denom = float(count_pos + V + 1)\n",
    "neg_denom = float(count_neg + V + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log probabities\n",
    "pos_prob = data_pos.map(lambda x: (x[0], np.log(float(x[1] + 1)/pos_denom)))\n",
    "\n",
    "neg_prob = data_neg.map(lambda x: (x[0], np.log(float(x[1] + 1)/neg_denom))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fawn', -12.078744828024506),\n",
       " (u'hazenut', -12.078744828024506),\n",
       " (u'antiamericans', -12.078744828024506),\n",
       " (u'divinely', -11.673279719916343),\n",
       " (u'blackend', -12.078744828024506),\n",
       " (u'resist', -10.373996735786081),\n",
       " (u'sahan', -11.673279719916343),\n",
       " (u'joshua', -11.673279719916343),\n",
       " (u'needlessly', -12.078744828024506),\n",
       " (u'advices', -12.078744828024506)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_prob.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_prob = dict(pos_prob.collect())\n",
    "neg_prob = dict(neg_prob.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# broadcast = shared by all nodes\n",
    "pos_prob_b = sc.broadcast(pos_prob)\n",
    "neg_prob_b = sc.broadcast(neg_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1277\n",
      "1277\n"
     ]
    }
   ],
   "source": [
    "test_raw_pos = sc.textFile(test_path + \"pos/*.txt\")\n",
    "test_raw_neg = sc.textFile(test_path + \"neg/*.txt\")\n",
    "\n",
    "test_raw_pos = test_raw_pos.sample(False, 0.1, 1)\n",
    "test_raw_neg = test_raw_neg.sample(False, 0.1, 1)\n",
    "\n",
    "num_partitions = 8\n",
    "test_raw_pos = test_raw_pos.repartition(num_partitions)\n",
    "test_raw_neg = test_raw_neg.repartition(num_partitions)\n",
    "\n",
    "print(test_raw_pos.count())\n",
    "print(test_raw_neg.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_class(doc):\n",
    "    doc_words = [words(w) for w in doc.split(\" \") if w is not None]\n",
    "    doc_words = [w for w in doc_words if w is not None]\n",
    "    doc_words= bigram_mapping(doc_words, bigrams + bigrams_neg)\n",
    "\n",
    "    counts = Counter(doc_words)\n",
    "    log_pos = 0.0\n",
    "    log_neg = 0.0\n",
    "    for w in counts:\n",
    "        log_pos += counts[w]* pos_prob_b.value.get(w, np.log(1.0/pos_denom))\n",
    "        log_neg += counts[w]* neg_prob_b.value.get(w, np.log(1.0/neg_denom))\n",
    "    if log_pos > log_neg:\n",
    "        return \"pos\"\n",
    "    return \"neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'pos']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pos_res = test_raw_pos.map(pred_class)\n",
    "test_pos_res.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 283, 'pos': 994}\n"
     ]
    }
   ],
   "source": [
    "test_pos_res = test_raw_pos.map(pred_class).map(lambda x: (x, 1)).reduceByKey(lambda x,y:x+y)\n",
    "pos_results = dict(test_pos_res.collect())\n",
    "print(pos_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 1125, 'pos': 152}\n"
     ]
    }
   ],
   "source": [
    "test_neg_res = test_raw_neg.map(pred_class).map(lambda x: (x, 1)).reduceByKey(lambda x,y:x+y)\n",
    "neg_results = dict(test_neg_res.collect())\n",
    "print(neg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829678935004\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "total = sum(neg_results.values()) + sum(pos_results.values())\n",
    "acc = float(neg_results[\"neg\"] + pos_results[\"pos\"]) / float(total)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
